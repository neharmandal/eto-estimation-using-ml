{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee179a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee6c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_2_year(date):\n",
    "    return(date.year)\n",
    "\n",
    "def datetojd(stddate): # Date to Julian day\n",
    "    sdtdate = stddate.timetuple()\n",
    "    jdate = sdtdate.tm_yday\n",
    "    return(jdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899abd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "\n",
    "# Define the working directory path here\n",
    "wd = \"/path/to/working/directory\"\n",
    "dataset = pd.read_csv(wd+\"Pusa_data.csv\")\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
    "dataset.insert(loc= 1, column= \"Year\", value= dataset['Date'].dt.year)\n",
    "dataset.insert(loc= 2, column= \"Jday\", value= dataset['Date'].apply(datetojd))\n",
    "\n",
    "# dropping the rows having NaN values\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# To reset the indices\n",
    "dataset = dataset.reset_index(drop = True)\n",
    "\n",
    "# Spliting Train and test set\n",
    "train = dataset[dataset[\"Year\"] < 2015] # Trainig set from 2010 to 2014\n",
    "test = dataset[dataset[\"Year\"] >= 2015] # Test set from 2015 to 2017\n",
    "\n",
    "X_train = train[['T_min','T_max','T_mean','Ra', 'Rs']].values\n",
    "X_test = test[['T_min','T_max','T_mean','Ra', 'Rs']].values\n",
    "y_train = train[['ETo']].values\n",
    "y_test = test[['ETo']].values\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "######################################################################################################\n",
    "# GBR\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [100,200,300,400,500, 1000, 1500, 2000],\n",
    "    'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05],\n",
    "    'max_depth' : [3, 5, 7, 9],\n",
    "    'min_samples_split' : [2, 4, 6, 8, 10]} # [5, 10,20, 25,30,40,50]\n",
    "\n",
    "\n",
    "regressor = GridSearchCV(GradientBoostingRegressor(random_state=123), param_grid, n_jobs=5, scoring='neg_mean_absolute_error', cv = 5, verbose=True)\n",
    "regressor.fit(X_train, y_train.ravel())\n",
    "\n",
    "# test result\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# train result\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "\n",
    "# Preparing Observed and Predicted Test dataset\n",
    "y_pred = pd.DataFrame({\"Predicted\": y_pred})\n",
    "y_test = pd.DataFrame({\"Observed\": y_test[:,0]})\n",
    "\n",
    "# Preparing Observed and Predicted Train dataset\n",
    "y_pred_train = pd.DataFrame({\"Predicted_Train\": y_pred_train})\n",
    "y_train = pd.DataFrame({\"Observed_Train\": y_train[:,0]})\n",
    "\n",
    "# Test Plot\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "plt.scatter(y_test, y_pred, \n",
    "            c =\"purple\", \n",
    "            linewidths = 0.5, \n",
    "            marker =\"o\", \n",
    "            edgecolor =\"black\", \n",
    "            s = 50)\n",
    "plt.xlabel('Observed PET')\n",
    "plt.ylabel('Predicted PET')\n",
    "plt.text(0.7*y_test.max(), 1.1*y_pred.min(), 'R-sq = %0.3f' % r_squared)\n",
    "fig1 = plt.gcf()\n",
    "fig1.set_size_inches(4.5, 4.5)\n",
    "plt.show()\n",
    "plt.draw()\n",
    "\n",
    "# Train plot\n",
    "r_squared = r2_score(y_train, y_pred_train)\n",
    "\n",
    "plt.scatter(y_train, y_pred_train, \n",
    "            c =\"forestgreen\", \n",
    "            linewidths = 0.5, \n",
    "            marker =\"o\", \n",
    "            edgecolor =\"black\", \n",
    "            s = 50)\n",
    "plt.xlabel('Observed PET')\n",
    "plt.ylabel('Predicted PET')\n",
    "plt.text(0.7*y_test.max(), 1.1*y_pred.min(), 'R-sq = %0.3f' % r_squared)\n",
    "fig1 = plt.gcf()\n",
    "fig1.set_size_inches(4.5, 4.5)\n",
    "plt.show()\n",
    "plt.draw()\n",
    "\n",
    "# Export Observed and Predicted dataset\n",
    "df1 = pd.concat([y_test, y_pred], axis=1)\n",
    "df2 = pd.concat([y_train, y_pred_train], axis=1)\n",
    "df1.to_csv(wd+\"Radiation_based_GBR_Test.csv\", index = False, header=True)\n",
    "df2.to_csv(wd+\"Radiation_based_GBR_Train.csv\", index = False, header=True)\n",
    "\n",
    "# Best parameter\n",
    "print(regressor.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
