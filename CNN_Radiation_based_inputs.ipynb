{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2319eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from sklearn.svm import SVR\n",
    "from numpy import std\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_2_year(date):\n",
    "    return(date.year)\n",
    "\n",
    "def datetojd(stddate): # Date to Julian day\n",
    "    sdtdate = stddate.timetuple()\n",
    "    jdate = sdtdate.tm_yday\n",
    "    return(jdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d298567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "\n",
    "# Define the working directory path here\n",
    "wd = \"/path/to/working/directory\"\n",
    "dataset = pd.read_csv(wd+\"Pusa_data.csv\")\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
    "dataset.insert(loc= 1, column= \"Year\", value= dataset['Date'].dt.year)\n",
    "dataset.insert(loc= 2, column= \"Jday\", value= dataset['Date'].apply(datetojd))\n",
    "\n",
    "# dropping the rows having NaN values\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# To reset the indices\n",
    "dataset = dataset.reset_index(drop = True)\n",
    "\n",
    "# Spliting Train and test set\n",
    "train = dataset[dataset[\"Year\"] < 2015] # Trainig set from 2010 to 2014\n",
    "test = dataset[dataset[\"Year\"] >= 2015] # Test set from 2015 to 2017\n",
    "\n",
    "X_train = train[['T_min','T_max','T_mean','Ra', 'Rs']].values\n",
    "X_test = test[['T_min','T_max','T_mean','Ra', 'Rs']].values\n",
    "y_train = train[['ETo']].values\n",
    "y_test = test[['ETo']].values\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "######################################################################################################\n",
    "# CNN\n",
    "\n",
    "def get_reg(n_neurons_1, n_neurons_2): #, compile_kwargs: Dict[str, Any]\n",
    "    # Initializing the CNN\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model.add(Conv1D(n_neurons_1, 2, activation=\"relu\", input_shape=(X_train.shape[1],1)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(n_neurons_2, activation=\"relu\"))\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compliling the CNN\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model    \n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "reg = KerasRegressor(\n",
    "    model=get_reg,\n",
    "    loss=\"mse\",\n",
    "    optimizer=\"adam\",\n",
    "    optimizer__learning_rate=0.001,\n",
    "    metrics=[KerasRegressor.r_squared],\n",
    "    n_neurons_1 = 12,\n",
    "    n_neurons_2 = 96,\n",
    "    epochs = 200,\n",
    "    batch_size=32,\n",
    "    random_state = 123,\n",
    ")\n",
    "\n",
    "# Set the parameters for cross-validation\n",
    "params = {\n",
    "    'model__n_neurons_1': [12, 24, 48, 96],\n",
    "    'model__n_neurons_2': [12, 24, 48, 96]\n",
    "}\n",
    "\n",
    "regressor = GridSearchCV(reg, params, n_jobs=5,  cv = 5, verbose=True, )\n",
    "\n",
    "regressor.fit(X_train, y_train, workers=10, use_multiprocessing= False)\n",
    "\n",
    "# test result\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# train result\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "\n",
    "# Preparing Observed and Predicted Test dataset\n",
    "y_pred = pd.DataFrame({\"Predicted\": y_pred[:,0]})\n",
    "y_test = pd.DataFrame({\"Observed\": y_test[:,0]})\n",
    "\n",
    "# Preparing Observed and Predicted Train dataset\n",
    "y_pred_train = pd.DataFrame({\"Predicted_Train\": y_pred_train[:,0]})\n",
    "y_train = pd.DataFrame({\"Observed_Train\": y_train[:,0]})\n",
    "\n",
    "# Test Plot\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "plt.scatter(y_test, y_pred, \n",
    "            c =\"purple\", \n",
    "            linewidths = 0.5, \n",
    "            marker =\"o\", \n",
    "            edgecolor =\"black\", \n",
    "            s = 50)\n",
    "plt.xlabel('Observed PET')\n",
    "plt.ylabel('Predicted PET')\n",
    "plt.text(0.7*y_test.max(), 1.1*y_pred.min(), 'R-sq = %0.3f' % r_squared)\n",
    "fig1 = plt.gcf()\n",
    "fig1.set_size_inches(4.5, 4.5)\n",
    "plt.show()\n",
    "plt.draw()\n",
    "\n",
    "# Train plot\n",
    "r_squared = r2_score(y_train, y_pred_train)\n",
    "\n",
    "plt.scatter(y_train, y_pred_train, \n",
    "            c =\"forestgreen\", \n",
    "            linewidths = 0.5, \n",
    "            marker =\"o\", \n",
    "            edgecolor =\"black\", \n",
    "            s = 50)\n",
    "plt.xlabel('Observed PET')\n",
    "plt.ylabel('Predicted PET')\n",
    "plt.text(0.7*y_test.max(), 1.1*y_pred.min(), 'R-sq = %0.3f' % r_squared)\n",
    "fig1 = plt.gcf()\n",
    "fig1.set_size_inches(4.5, 4.5)\n",
    "plt.show()\n",
    "plt.draw()\n",
    "\n",
    "# Export Observed and Predicted dataset\n",
    "df1 = pd.concat([y_test, y_pred], axis=1)\n",
    "df2 = pd.concat([y_train, y_pred_train], axis=1)\n",
    "df1.to_csv(wd+\"Radiation_based_CNN_Test.csv\", index = False, header=True)\n",
    "df2.to_csv(wd+\"Radiation_based_CNN_Train.csv\", index = False, header=True)\n",
    "\n",
    "# Best parameter\n",
    "print(regressor.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
